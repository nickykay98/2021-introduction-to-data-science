{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training Example\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load libraries for creating a xgboost model of the iris dataset \r\n",
    "from sklearn import datasets\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from xgboost import XGBClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load the iris data as an example\r\n",
    "# NOTE: For the assignment, you will need to use the data from Kaggle \r\n",
    "#       and process the text data into a usable format and then create \r\n",
    "#       a ML model that satisfies the assignment task!\r\n",
    "iris = datasets.load_iris() \r\n",
    "X = iris.data                \r\n",
    "y = iris.target             "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Split data into test and train \r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Create XGBoost classifier \r\n",
    "xgbClf = XGBClassifier(use_label_encoder = False)\r\n",
    "xgbClf.fit(X_train, y_train)\r\n",
    "xgbClf.save_model(\"model.json\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[18:54:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Deployment via Jupyter Notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Load workspace\r\n",
    "from azureml.core import Workspace\r\n",
    "ws = Workspace.from_config(path = \"config.json\")\r\n",
    "print(ws)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "Note, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\n",
      "You have logged in. Now let us find all the subscriptions to which you have access...\n",
      "Interactive authentication successfully completed.\n",
      "Workspace.create(name='MSA-ModelDeployment', subscription_id='1728fb6f-0674-4adc-b1a8-0462995e20a5', resource_group='MSA-ModelDeployment')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from azureml.core.model import Model\r\n",
    "\r\n",
    "# Register model (have to do this in assignment too)\r\n",
    "model = Model.register(ws, model_name = \"iris-xgboost\", model_path = \"model.json\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Registering model iris-xgboost\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from azureml.core import Environment\r\n",
    "from azureml.core.conda_dependencies import CondaDependencies\r\n",
    "from azureml.core.model import InferenceConfig\r\n",
    "\r\n",
    "# Create environment\r\n",
    "# env = Environment.from_existing_conda_environment(name = \"iris-xgboost\", conda_environment_name = \"azure\")\r\n",
    "# for assignment, create own environment with packages you need\r\n",
    "\r\n",
    "env = Environment(name = \"iris-xgboost\")\r\n",
    "conda_dep = CondaDependencies()\r\n",
    "conda_dep.add_conda_package(\"numpy\")\r\n",
    "conda_dep.add_conda_package(\"xgboost\")\r\n",
    "env.python.conda_dependencies = conda_dep\r\n",
    "\r\n",
    "# entry script tells AZ what to do with model\r\n",
    "dummy_inference_config = InferenceConfig(environment = env, source_directory = \"./source_dir\", entry_script = \"./echo_score.py\",)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# deploying model\r\n",
    "from azureml.core.webservice import AciWebservice\r\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\r\n",
    "service = Model.deploy(\r\n",
    "    ws,\r\n",
    "    \"iris-xgboost\",\r\n",
    "    [model],\r\n",
    "    dummy_inference_config,\r\n",
    "    aci_config,\r\n",
    "    overwrite = True,\r\n",
    ")\r\n",
    "service.wait_for_deployment(show_output = True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-07-26 18:59:24+12:00 Creating Container Registry if not exists..\n",
      "2021-07-26 18:59:39+12:00 Registering the environment..\n",
      "2021-07-26 18:59:42+12:00 Building image..\n",
      "2021-07-26 19:10:28+12:00 Generating deployment configuration.\n",
      "2021-07-26 19:10:29+12:00 Submitting deployment to compute.\n",
      "2021-07-26 19:10:39+12:00 Checking the status of deployment iris-xgboost.\n",
      "2021-07-26 19:13:37+12:00 Checking the status of inference endpoint iris-xgboost.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import requests\r\n",
    "import json\r\n",
    "\r\n",
    "uri = service.scoring_uri\r\n",
    "requests.get(\"<API Endpoint Here>\")\r\n",
    "headers = {\"Content-Type\": \"application/json\"}\r\n",
    "data = {\r\n",
    "    \"data\": [[6.1, 2.8, 4.7, 1.2]], # can replace this with string for NLP stuff, output should be a readability score\r\n",
    "}\r\n",
    "data = json.dumps(data)\r\n",
    "response = requests.post(uri, data = data, headers = headers)\r\n",
    "print(response.json())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['versicolor']\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdb671202a387ebf0bc7bf04476cbafa528fae566193c2efe94e2aaf8539be45"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
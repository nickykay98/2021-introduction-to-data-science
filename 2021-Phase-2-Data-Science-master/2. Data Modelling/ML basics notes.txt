44: common words have high counts and don't contribute much to meaning of phrase, not useful for algorithm
45: TF-IDF minimises impact of common words and vice versa
46: bottom table is TF-IDF (can use in sklearn) - easier to see what phrases are about, ML algorithm might have easier time figuring out sentiment/meaning
48: similar words are grouped together, could also do vector arithmetic on them (word2vec - slide 50)


FOR ASSIGNMENT:
- Need to get data in the right format for model (can't feed whole book into it)
- Model output is not well-defined, need to come up with a way of converting output into something useful
- Transform text into all lowercase, combine similar words (stemming) - slide 47
- Scale inputs for NNs (like b/w 0-1 , or mean of 0 and std of 1)
- Submit notebook like 2.ipynb but better commented/more markdown (explain what you did, how you tested the models, different variations etc)
- Get a better score than the 2.ipynb notebook (0.806 RMSE, lower is better)
- Advanced requirement: huggingface model outputs a folder of files, not just json (like XGboost), account for this - see 4. example.ipynb
- Will be asked in presentation (going through what you did, any interesting/advanced things you did) about either technical part of business case or scraping part 
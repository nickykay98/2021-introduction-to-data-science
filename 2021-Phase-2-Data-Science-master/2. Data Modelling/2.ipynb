{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as numpy\r\n",
    "import pandas as pd\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_data = pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')\r\n",
    "test_data = pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vectoriser = TfidfVectorizer()\r\n",
    "x = vectoriser.fit_transform(train_data['excerpt'].values)\r\n",
    "# x should be 2834 x 26833 i.e. 26833 words, too many to deal with"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(vectoriser.get_feature_names()) \r\n",
    "# gets vector like on slide 46, removes punctuation but not other stuff like numbers \r\n",
    "# so use the below to limit to just words and only get top 2000 words\r\n",
    "# vectoriser converts to lowercase by default\r\n",
    "\r\n",
    "vectoriser = TfidfVectorizer(stop_words = 'english', max_features = 2000, lowercase = True)\r\n",
    "x = vectoriser.fit_transform(train_data['excerpt'].values)\r\n",
    "\r\n",
    "# BUT above is wrong, shouldn't be vectorising on whole training set, should have only fitted on X_train and at the end, train on entire dataset - leads to data leakage, validation data is in vectorising stage here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = train_data.loc[:,'target']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(train_data[excerpt]['0']) # shows first paragraph\r\n",
    "data = vectoriser.transform(train_data[excerpt][['0']]).toarray() # vectoriser expects a list\r\n",
    "pd.DataFrame(data).T.plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create ML model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "regr = MLPRegressor(hidden_layer_size=(512,1024,512))\r\n",
    "regr.fit(X_train, y_train) # might need to do X_train.toarray()\r\n",
    "regr.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# check performance\r\n",
    "regr.score(X_train, y_train)\r\n",
    "regr.score(X_test, y_test) # likely lower i.e. overfitting"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "training_preds = regr.predict(X_train)\r\n",
    "plt.plot(y_train, training_preds, 'bo') # real vs predicted label\r\n",
    "\r\n",
    "test_preds = regr.predict(X_test)\r\n",
    "plt.plot(y_test, test_preds, 'bo') # will be worse than training (more scattered)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import mean_squared_error\r\n",
    "mean_squared_error(y_train, training_preds)\r\n",
    "mean_squared_error(y_test, test_preds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train one last time with entire dataset\r\n",
    "regr.fit(X, y)\r\n",
    "# train with actual test set\r\n",
    "X_test = vectoriser.transorm(test_data['excerpt'])\r\n",
    "test_preds = regr.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for kaggle submission\r\n",
    "predictions = pd.DataFrame()\r\n",
    "predictions['id'] = test_df['id']\r\n",
    "predictions['target'] = test_preds\r\n",
    "predictions.to_csv('submission.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('venv')"
  },
  "interpreter": {
   "hash": "c2efe957cf3b2ef82c45a23ebddb5bf2eaaea2ad4fd3db4a35b02391cee243cb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}